{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Evaluation Pipeline\n",
    "**Please review the code cell below. At a minimum, you must enter a directory where output should be saved, and also tell this notebook where your model data is**. Then just run the notebook.\n",
    "\n",
    "Look for the .txt and .output files in your working directly. Those are the results.\n",
    "\n",
    "This pipeline is heavily reliant on other functions scattered throughout the repo, so please be sure you haven't moved it anywhere else. It is also heavily reliant on the model structure and output files generated during training with our base code. It is finicky enough that if you have any issues, it's probably easiest to just ask me to fix it (or at least show me the error)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter the directory where you would like final result files to be saved.\n",
    "WORKING_DIR = 'C:/Users/eweeding/Documents/MSE/DeepLearning/FinalProject'\n",
    "\n",
    "# Now create a dictionary of lists with info on the models you want to compare\n",
    "# Format is: { model_name_str : [model_pt_path, model_bin_path] }\n",
    "# You can add as many as you want! Theoretically.\n",
    "model_list = {}\n",
    "model_list['VanillaRNN'] = [WORKING_DIR+'/vanilla-rnn-RNN_RELU-model.pt', WORKING_DIR+'/vanilla-rnn-RNN_RELU-data.bin']\n",
    "model_list['LSTM'] = [WORKING_DIR+'/LSTM-1-model.pt', WORKING_DIR+'/LSTM-1-data.bin']\n",
    "model_list['LCRNN'] = [WORKING_DIR+'/20-01-13-Tanh-outside-lcRNN_RELU-model.pt', WORKING_DIR+'/20-01-13-Tanh-outside-lcRNN_RELU-data.bin']\n",
    "model_list['MatureLCRNN'] = [WORKING_DIR+'/20-01-13-Tanh-outside-lcRNN_RELU-model (2).pt', WORKING_DIR+'/20-01-13-Tanh-outside-lcRNN_RELU-data (2).bin']\n",
    "\n",
    "# Set analysis mode. Options are 'overall' (default) or 'full'\n",
    "MODE = 'overall'\n",
    "#MODE = 'full'\n",
    "\n",
    "# If ANIM == True, examine the effects of animacy on the results. Default is False.\n",
    "ANIM = False\n",
    "\n",
    "# If NPI_SKIP == True, skip analysis of NPI. Analysis of these items seems to behave strangely if using a subset of test sentences.\n",
    "NPI_SKIP = True\n",
    "\n",
    "### OPTIONAL ###\n",
    "# Other paths you may need or want to change depending on your setup:\n",
    "TEMPLATE_DIR = './EMNLP2018/templates' # Location where the paired sentence dataset should be\n",
    "OUTPUT_FILE = 'all_test_sents.txt'     # Name of .txt file which will contain all test sentences, saved in TEMPLATE_DIR\n",
    "MODEL_TYPE = 'RNN'                     # Model type. For now, only single-task RNN is supported, so don't change this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 0: Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU available: True\n"
     ]
    }
   ],
   "source": [
    "# Import statements\n",
    "import logging\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import operator\n",
    "import os\n",
    "import pandas as pd\n",
    "import sys\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from src.tester.TestWriter import TestWriter\n",
    "from src.template.TestCases import TestCase\n",
    "\n",
    "# Import a module within the base code\n",
    "# Pathing workaround due to hyphens in folder name\n",
    "sys.path.append(os.path.join(os.getcwd(), 'word-language-model'))\n",
    "import data\n",
    "\n",
    "# Suppress some intermediate messages\n",
    "logging.disable(sys.maxsize)\n",
    "\n",
    "# Check for GPU\n",
    "gpu_avail = torch.cuda.is_available()\n",
    "print('GPU available:', gpu_avail)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Generate paired sentences\n",
    "This generates the sentences for testing. These already exist in `./EMNLP2018/templates`, but you may need to generate them yourself if Pickle is behaving strangely with the downloaded files based on your OS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "case: obj_rel_across_anim\n",
      "case: obj_rel_within_anim\n",
      "case: obj_rel_across_inanim\n",
      "case: obj_rel_within_inanim\n",
      "case: subj_rel\n",
      "case: prep_anim\n",
      "case: prep_inanim\n",
      "case: obj_rel_no_comp_across_anim\n",
      "case: obj_rel_no_comp_within_anim\n",
      "case: obj_rel_no_comp_across_inanim\n",
      "case: obj_rel_no_comp_within_inanim\n",
      "case: simple_agrmt\n",
      "case: sent_comp\n",
      "case: vp_coord\n",
      "case: long_vp_coord\n",
      "case: reflexives_across\n",
      "case: simple_reflexives\n",
      "case: reflexive_sent_comp\n",
      "case: npi_across_anim\n",
      "case: npi_across_inanim\n",
      "case: simple_npi_anim\n",
      "case: simple_npi_inanim\n"
     ]
    }
   ],
   "source": [
    "%run ./src/make_templates.py $TEMPLATE_DIR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Test a model on the sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions for calculating complexity measures\n",
    "def get_entropy(o):\n",
    "    probs = nn.functional.softmax(o,dim=0)\n",
    "    logprobs = nn.functional.log_softmax(o,dim=0)\n",
    "    return -1 * torch.sum(probs * logprobs)\n",
    "\n",
    "\n",
    "def get_surps(o):\n",
    "    logprobs = nn.functional.log_softmax(o,dim=0)\n",
    "    return -1 * logprobs\n",
    "\n",
    "\n",
    "def get_complexity_apply(o,t,sentid,corpus,model_name,tags=False):\n",
    "    Hs = torch.squeeze(apply(get_entropy,o))\n",
    "    surps = apply(get_surps,o)    \n",
    "    for corpuspos, targ in enumerate(t):\n",
    "        if tags:\n",
    "            word = corpus.dictionary.idx2tag[int(targ)]\n",
    "        else:\n",
    "            word = corpus.dictionary.idx2word[int(targ)]\n",
    "        if word == '<eos>' or word == '<EOS>':\n",
    "            # Don't output the complexity of EOS\n",
    "            continue\n",
    "        surp = surps[corpuspos][int(targ)]        \n",
    "        with open(WORKING_DIR+'/'+model_name+'.output', 'a') as f:\n",
    "            f.write('\\n' + str(word)+' '+str(sentid)+' '+str(corpuspos)+' '+str(len(word))+' '+str(float(surp))+' '+str(float(Hs[corpuspos])))\n",
    "\n",
    "            \n",
    "def apply(func, M):\n",
    "    tList = [func(m) for m in torch.unbind(M,dim=0) ]\n",
    "    res = torch.stack(tList)\n",
    "    return res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core testing functions\n",
    "def repackage_hidden(h):\n",
    "    if isinstance(h, torch.Tensor):\n",
    "        return h.detach()\n",
    "    else:\n",
    "        return tuple(repackage_hidden(v) for v in h)  \n",
    "    \n",
    "    \n",
    "def test_get_batch(source, evaluation=False):\n",
    "    if isinstance(source, tuple):\n",
    "        seq_len = len(source[0]) - 1\n",
    "        data = Variable(source[0][:seq_len], requires_grad=False)\n",
    "        target = Variable(source[1][:seq_len], requires_grad=False)\n",
    "    else:\n",
    "        seq_len = len(source) - 1\n",
    "        data = Variable(source[:seq_len], requires_grad=False)\n",
    "        target = Variable(source[1:1+seq_len].view(-1))\n",
    "    if gpu_avail:\n",
    "        return data.cuda(), target.cuda()\n",
    "    else:\n",
    "        return data, target\n",
    "\n",
    "    \n",
    "def test_evaluate(test_lm_sentences, test_ccg_sentences, lm_data_source, ccg_data_source, model, model_name, corpus):\n",
    "    model.eval()\n",
    "    criterion = nn.CrossEntropyLoss()    \n",
    "    total_loss = 0.\n",
    "    ntokens = len(corpus.dictionary)\n",
    "    \n",
    "    with open(WORKING_DIR+'/'+model_name+'.output', 'w') as f:\n",
    "        f.write('word sentid sentpos wlen surp entropy')    \n",
    "\n",
    "    for i in range(len(lm_data_source)+len(ccg_data_source)):\n",
    "        if i % 1000 == 0:\n",
    "            print(f'{i} / {len(lm_data_source)} sentences')\n",
    "            \n",
    "        if i >= len(lm_data_source):\n",
    "            sent_ids = ccg_data_source[i-len(lm_data_source)]\n",
    "            sent = test_ccg_sentences[i-len(lm_data_source)]\n",
    "        else:\n",
    "            sent_ids = lm_data_source[i]\n",
    "            sent = test_lm_sentences[i]\n",
    "            \n",
    "        if gpu_avail:\n",
    "            sent_ids = sent_ids.cuda()\n",
    "            \n",
    "        hidden = model.init_hidden(1)\n",
    "        data, targets = test_get_batch(sent_ids, evaluation=True)\n",
    "        data = data.unsqueeze(1)\n",
    "        output, hidden = model(data, hidden)\n",
    "        output_flat = output.view(-1, ntokens)\n",
    "        curr_loss = criterion(output_flat, targets).item()\n",
    "        total_loss += curr_loss\n",
    "\n",
    "        # Get word-level complexity metrics\n",
    "        if i >= len(lm_data_source):\n",
    "            get_complexity_apply(output_flat,targets,i-len(lm_data_source),corpus,model_name,tags=True)\n",
    "        else:\n",
    "            get_complexity_apply(output_flat,targets,i,corpus,model_name)\n",
    "        hidden = repackage_hidden(hidden)\n",
    "\n",
    "    return total_loss / (len(lm_data_source)+len(ccg_data_source))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A main function that coordinates testing\n",
    "def run_main(model_name, save, save_lm_data, lm_data, testfname):\n",
    "    corpus = data.SentenceCorpus(lm_data, False, save_lm_data, True, testfname=testfname)\n",
    "    test_lm_sentences, test_lm_data = corpus.test_lm\n",
    "    test_ccg_sentences = []\n",
    "    test_ccg_data = []    \n",
    "\n",
    "    # Load the saved model\n",
    "    if gpu_avail:\n",
    "        model = torch.load(save, map_location = 'cuda:0')\n",
    "    else:\n",
    "        model = torch.load(save, map_location = 'cpu')    \n",
    "    print(model)    \n",
    "\n",
    "    # Run on test data\n",
    "    test_loss = test_evaluate(test_lm_sentences, test_ccg_sentences, test_lm_data, test_ccg_data, model, model_name, corpus)\n",
    "    print('End of testing. Test Loss {:5.2f} | Test PPL {:8.2f}'.format(test_loss, math.exp(test_loss)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final functions to combine model testing and scoring on sentences\n",
    "def score_rnn(model_name):\n",
    "    print('Scoring '+model_name)\n",
    "    with open(WORKING_DIR+'/'+model_name+'.output', 'r') as f:\n",
    "        all_scores = {}\n",
    "        first = False\n",
    "        score = 0.\n",
    "        sent = []\n",
    "        prev_sentid = -1\n",
    "        for line in f:\n",
    "            if not first:\n",
    "                first = True\n",
    "                continue\n",
    "            if first and len(line.strip().split()) == 6 and \"torch.cuda\" not in line:\n",
    "                wrd, sentid, wrd_score = [line.strip().split()[i] for i in [0,1,4]]\n",
    "                score = -1 * float(wrd_score) # multiply by -1 to turn surps back into logprobs\n",
    "                sent.append((wrd, score))\n",
    "                if wrd == \".\":\n",
    "                    name_found = False                    \n",
    "                    for (k1,v1) in sorted(name_lengths.items(), key=operator.itemgetter(1)):\n",
    "                        if float(sentid) < v1 and not name_found:\n",
    "                            name_found = True\n",
    "                            if k1 not in all_scores:\n",
    "                                all_scores[k1] = {}\n",
    "                            key_found = False\n",
    "                            for (k2,v2) in sorted(key_lengths[k1].items(), key=operator.itemgetter(1)):\n",
    "                                if int(sentid) <  v2 and not key_found:\n",
    "                                    key_found = True\n",
    "                                    if k2 not in all_scores[k1]:\n",
    "                                        all_scores[k1][k2] = []\n",
    "                                    all_scores[k1][k2].append(sent)\n",
    "                    sent = []\n",
    "                    prev_sentid = float(sentid)\n",
    "    return all_scores\n",
    "\n",
    "\n",
    "def test_LM(model_name, model_files):      \n",
    "    print('Testing '+model_name)\n",
    "    run_main(model_name, model_files[0], model_files[1], TEMPLATE_DIR, OUTPUT_FILE)\n",
    "    results = score_rnn(model_name)\n",
    "    with open(WORKING_DIR+'/'+model_name+'_results.pickle', 'wb') as f:\n",
    "        pickle.dump(results, f)\n",
    "    print('End of scoring.\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing VanillaRNN\n",
      "RNNModel(\n",
      "  (drop): Dropout(p=0.2, inplace=False)\n",
      "  (encoder): Embedding(50001, 650)\n",
      "  (rnn): RNN(650, 650, num_layers=2, dropout=0.2)\n",
      "  (decoder): Linear(in_features=650, out_features=50001, bias=True)\n",
      ")\n",
      "0 / 11916 sentences\n",
      "1000 / 11916 sentences\n",
      "2000 / 11916 sentences\n",
      "3000 / 11916 sentences\n",
      "4000 / 11916 sentences\n",
      "5000 / 11916 sentences\n",
      "6000 / 11916 sentences\n",
      "7000 / 11916 sentences\n",
      "8000 / 11916 sentences\n",
      "9000 / 11916 sentences\n",
      "10000 / 11916 sentences\n",
      "11000 / 11916 sentences\n",
      "End of testing. Test Loss  6.94 | Test PPL  1035.36\n",
      "Scoring VanillaRNN\n",
      "End of scoring.\n",
      "\n",
      "Testing LSTM\n",
      "RNNModel(\n",
      "  (drop): Dropout(p=0.2, inplace=False)\n",
      "  (encoder): Embedding(50001, 650)\n",
      "  (rnn): LSTM(650, 650, num_layers=2, dropout=0.2)\n",
      "  (decoder): Linear(in_features=650, out_features=50001, bias=True)\n",
      ")\n",
      "0 / 11916 sentences\n",
      "1000 / 11916 sentences\n",
      "2000 / 11916 sentences\n",
      "3000 / 11916 sentences\n",
      "4000 / 11916 sentences\n",
      "5000 / 11916 sentences\n",
      "6000 / 11916 sentences\n",
      "7000 / 11916 sentences\n",
      "8000 / 11916 sentences\n",
      "9000 / 11916 sentences\n",
      "10000 / 11916 sentences\n",
      "11000 / 11916 sentences\n",
      "End of testing. Test Loss  6.71 | Test PPL   818.53\n",
      "Scoring LSTM\n",
      "End of scoring.\n",
      "\n",
      "Testing LCRNN\n",
      "RNNModel(\n",
      "  (drop): Dropout(p=0.2, inplace=False)\n",
      "  (encoder): Embedding(50001, 650)\n",
      "  (rnn): RNN(650, 650, num_layers=2, dropout=0.2)\n",
      "  (decoder): Linear(in_features=650, out_features=50001, bias=True)\n",
      "  (LCLs_outside): LocallyConnectedMLP(\n",
      "    (lcmlp): Sequential(\n",
      "      (locallyconnected1): LocallyConnectedLayer1d()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "0 / 11916 sentences\n",
      "1000 / 11916 sentences\n",
      "2000 / 11916 sentences\n",
      "3000 / 11916 sentences\n",
      "4000 / 11916 sentences\n",
      "5000 / 11916 sentences\n",
      "6000 / 11916 sentences\n",
      "7000 / 11916 sentences\n",
      "8000 / 11916 sentences\n",
      "9000 / 11916 sentences\n",
      "10000 / 11916 sentences\n",
      "11000 / 11916 sentences\n",
      "End of testing. Test Loss 14.60 | Test PPL 2188060.20\n",
      "Scoring LCRNN\n",
      "End of scoring.\n",
      "\n",
      "Testing MatureLCRNN\n",
      "RNNModel(\n",
      "  (drop): Dropout(p=0.2, inplace=False)\n",
      "  (encoder): Embedding(50001, 650)\n",
      "  (rnn): RNN(650, 650, num_layers=2, dropout=0.2)\n",
      "  (decoder): Linear(in_features=650, out_features=50001, bias=True)\n",
      "  (LCLs_outside): LocallyConnectedMLP(\n",
      "    (lcmlp): Sequential(\n",
      "      (locallyconnected1): LocallyConnectedLayer1d()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "0 / 11916 sentences\n",
      "1000 / 11916 sentences\n",
      "2000 / 11916 sentences\n",
      "3000 / 11916 sentences\n",
      "4000 / 11916 sentences\n",
      "5000 / 11916 sentences\n",
      "6000 / 11916 sentences\n",
      "7000 / 11916 sentences\n",
      "8000 / 11916 sentences\n",
      "9000 / 11916 sentences\n",
      "10000 / 11916 sentences\n",
      "11000 / 11916 sentences\n",
      "End of testing. Test Loss 14.45 | Test PPL 1883365.50\n",
      "Scoring MatureLCRNN\n",
      "End of scoring.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Select constructions to test (automatically selects all)\n",
    "writer = TestWriter(TEMPLATE_DIR, OUTPUT_FILE)\n",
    "testcase = TestCase()\n",
    "tests = testcase.all_cases\n",
    "all_test_sents = {}\n",
    "for test_name in tests:\n",
    "    test_sents = pickle.load(open(TEMPLATE_DIR+\"/\"+test_name+\".pickle\", 'rb'))\n",
    "    all_test_sents[test_name] = test_sents\n",
    "writer.write_tests(all_test_sents, 'word')\n",
    "name_lengths = writer.name_lengths\n",
    "key_lengths = writer.key_lengths\n",
    "\n",
    "# Finally, proceed with testing the model(s)\n",
    "for model_name, model_files in model_list.items():\n",
    "    test_LM(model_name, model_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Analyze the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions for higher level interpretation of model results\n",
    "def is_more_probable(sent_a, sent_b):\n",
    "    if len(sent_a) != len(sent_b):\n",
    "        print(\"ERROR: Mismatch in sentence lengths: (1) \"+sent_a+\" vs (2) \"+sent_b)\n",
    "    return sum([sent_a[i][1] for i in range(len(sent_a))]) > sum([sent_b[i][1] for i in range(len(sent_b))])\n",
    "\n",
    "\n",
    "def analyze_agrmt_results(results):\n",
    "    correct_sents = {}\n",
    "    incorrect_sents = {}\n",
    "    for case in results.keys():\n",
    "        correct_sents[case] = []\n",
    "        incorrect_sents[case] = []\n",
    "        for i in range(0,len(results[case]),2):\n",
    "            grammatical = results[case][i]\n",
    "            ungrammatical = results[case][i+1]\n",
    "            if is_more_probable(grammatical, ungrammatical):\n",
    "                correct_sents[case].append((grammatical, ungrammatical))\n",
    "            else:\n",
    "                incorrect_sents[case].append((grammatical, ungrammatical))\n",
    "    return correct_sents, incorrect_sents\n",
    "\n",
    "\n",
    "def analyze_npi_results(results):\n",
    "    options = ['gi_g', 'gi_i','iu_i','iu_u','gu_g','gu_u']\n",
    "    sentences = {}\n",
    "    for opt in options:\n",
    "        sentences[opt] = {}\n",
    "        for case in results.keys():\n",
    "            sentences[opt][case] = []\n",
    "    for case in results.keys():\n",
    "        for i in range(0,len(results[case]),3):\n",
    "            grammatical = results[case][i]\n",
    "            intrusive = results[case][i+1]\n",
    "            ungrammatical = results[case][i+2]\n",
    "            g_sent = grammatical\n",
    "            i_sent = intrusive\n",
    "            u_sent = ungrammatical\n",
    "            if is_more_probable(grammatical, intrusive):\n",
    "                sentences['gi_g'][case].append((g_sent, i_sent, u_sent))\n",
    "            else:\n",
    "                sentences['gi_i'][case].append((g_sent, i_sent, u_sent))\n",
    "            if is_more_probable(grammatical, ungrammatical):\n",
    "                sentences['gu_g'][case].append((g_sent, i_sent, u_sent))\n",
    "            else:\n",
    "                sentences['gu_u'][case].append((g_sent, i_sent, u_sent))\n",
    "            if is_more_probable(intrusive, ungrammatical):\n",
    "                sentences['iu_i'][case].append((g_sent, i_sent, u_sent))\n",
    "            else:\n",
    "                sentences['iu_u'][case].append((g_sent, i_sent, u_sent))\n",
    "    return [sentences[x] for x in options]\n",
    "\n",
    "\n",
    "def display_agrmt_results(name, sents, model_name):\n",
    "    correct_sents, incorrect_sents = sents\n",
    "    overall_correct = 0.\n",
    "    total = 0.\n",
    "    strings = {}\n",
    "    case_accs = {}\n",
    "    for case in correct_sents.keys():\n",
    "        if MODE == 'full':\n",
    "            string = \"\"\n",
    "            if len(correct_sents[case]) > 0:\n",
    "                for i in range(len(correct_sents[case][0][0])):\n",
    "                    if correct_sents[case][0][0][i][0] == correct_sents[case][0][1][i][0]:\n",
    "                        string += correct_sents[case][0][0][i][0] + \" \"\n",
    "                    else: string += correct_sents[case][0][0][i][0]+\"/*\"+correct_sents[case][0][1][i][0]+\" \"\n",
    "            else:\n",
    "                for i in range(len(incorrect_sents[case][0][0])):\n",
    "                    if incorrect_sents[case][0][0][i][0] == incorrect_sents[case][0][1][i][0]:\n",
    "                        string += incorrect_sents[case][0][0][i][0] + \" \"\n",
    "                    else: string += incorrect_sents[case][0][0][i][0]+\"/*\"+incorrect_sents[case][0][1][i][0]+\" \"\n",
    "            strings[case] = string[:-1]\n",
    "            case_accs[case] = float(len(correct_sents[case]))/(len(correct_sents[case])+len(incorrect_sents[case]))\n",
    "        overall_correct += len(correct_sents[case])\n",
    "        total += len(correct_sents[case]) + len(incorrect_sents[case])\n",
    "        \n",
    "    # Case-by-case accuracies\n",
    "    if MODE == 'full':\n",
    "        case_out = open(WORKING_DIR+'/'+model_name+'_case_accs.txt', 'w')\n",
    "        case_out.write(\"\\n##########\\n\" + name + \"\\n##########\\n\"+\"Overall acc: \"+str(float(overall_correct)/total)+\"\\n\")\n",
    "        for (case,score) in sorted(case_accs.items(), key=operator.itemgetter(1)):\n",
    "            case_out.write(str(case)+\":\\n\")\n",
    "            case_out.write(strings[case]+\": \"+str(round(score,4))+\"\\n\")\n",
    "        case_out.write(\"\\n\")\n",
    "        case_out.close()\n",
    "        \n",
    "    # Individual scores\n",
    "    if MODE == 'full':\n",
    "        fout = open(WORKING_DIR+'/'+model_name+'_individual_accs.txt', 'w')\n",
    "        fout.write(\"\\n##########\\n\" + name + \"\\n##########\\n\\n\")\n",
    "        fout.write(\"Examples that the LM predicts incorrectly:\\n\")\n",
    "        for case in incorrect_sents.keys():\n",
    "            count = 0\n",
    "            fout.write(case+\":\\n\")\n",
    "            for good, bad in incorrect_sents[case]:\n",
    "                if count < 5:\n",
    "                    fout.write(\"Grammatical:\"+str(round(sum([x[1] for x in good]),2))+\"\\n\")\n",
    "                    fout.write('\\t'.join([x[0] for x in good])+\"\\n\")\n",
    "                    fout.write('\\t'.join([str(round(x[1],2)) for x in good])+\"\\n\")\n",
    "                    fout.write(\"Ungrammatical:\"+str(round(sum([x[1] for x in bad]),2))+\"\\n\")\n",
    "                    fout.write('\\t'.join([x[0] for x in bad])+\"\\n\")\n",
    "                    fout.write('\\t'.join([str(round(x[1],2)) for x in bad])+\"\\n\")\n",
    "                    count += 1\n",
    "                else:\n",
    "                    break\n",
    "        fout.write(\"\\n\")\n",
    "        fout.close()\n",
    "    return float(overall_correct)/total\n",
    "\n",
    "\n",
    "def display_npi_results(name, sents, model_name):\n",
    "    gi_grammatical_sents, gi_intrusive_sents, iu_intrusive_sents, iu_ungrammatical_sents, gu_grammatical_sents, gu_ungrammatical_sents = sents\n",
    "    overall_gi = 0.\n",
    "    overall_iu = 0.\n",
    "    overall_gu= 0.\n",
    "    total_gi = 0.\n",
    "    total_iu = 0.\n",
    "    total_gu = 0.\n",
    "    strings = {}\n",
    "    gi_case_accs = {}\n",
    "    iu_case_accs = {}\n",
    "    gu_case_accs = {}\n",
    "    for case in gi_grammatical_sents.keys():\n",
    "        gi_case_accs[case] = {}\n",
    "        iu_case_accs[case] = {}\n",
    "        gu_case_accs[case] = {}        \n",
    "        if MODE == 'full':\n",
    "            if len(gi_grammatical_sents[case]) > 0:\n",
    "                string = ' '.join([x[0] for x in gi_grammatical_sents[case][0][0]]) + \" vs. \" + ' '.join([x[0] for x in gi_grammatical_sents[case][0][1]]) + \" vs. \" + ' '.join([x[0] for x in gi_grammatical_sents[case][0][2]])\n",
    "            else:\n",
    "                string = ' '.join([x[0] for x in gi_intrusive_sents[case][0][0]]) + \" vs. \" + ' '.join([x[0] for x in gi_intrusive_sents[case][0][1]]) + \" vs. \" + ' '.join([x[0] for x in gi_intrusive_sents[case][0][2]])\n",
    "            strings[case] = string\n",
    "            gi_case_accs[case] = float(len(gi_grammatical_sents[case]))/(len(gi_grammatical_sents[case])+len(gi_intrusive_sents[case]))\n",
    "            iu_case_accs[case] = float(len(iu_intrusive_sents[case]))/(len(iu_intrusive_sents[case])+len(iu_ungrammatical_sents[case]))\n",
    "            gu_case_accs[case] = float(len(gu_grammatical_sents[case]))/(len(gu_grammatical_sents[case])+len(gu_ungrammatical_sents[case]))\n",
    "        overall_gi += len(gi_grammatical_sents[case])\n",
    "        overall_iu += len(iu_intrusive_sents[case])\n",
    "        overall_gu += len(gu_grammatical_sents[case])\n",
    "        total_gi += len(gi_grammatical_sents[case]) + len(gi_intrusive_sents[case])\n",
    "        total_iu += len(iu_intrusive_sents[case]) + len(iu_ungrammatical_sents[case])\n",
    "        total_gu += len(gu_grammatical_sents[case]) + len(gu_ungrammatical_sents[case])\n",
    "        \n",
    "    # Case-by-case accuracies\n",
    "    if MODE == 'full':\n",
    "        case_out = open(WORKING_DIR+'/'+model_name+'_case_accs.txt', 'a')\n",
    "        case_out.write(\"\\n##########\\n\" + name + \"\\n##########\\n\" + \"Overall acc:\\n\")\n",
    "        case_out.write(\"OVERALL P(GRAMMATICAL) > P(INTRUSIVE): \"+str(float(overall_gi)/total_gi)+\"\\n\")\n",
    "        case_out.write(\"OVERALL P(INTRUSIVE) > P(UNGRAMMATICAL): \"+str(float(overall_iu)/total_iu)+\"\\n\")\n",
    "        case_out.write(\"OVERALL P(GRAMMATICAL) > P(UNGRAMMATICAL): \"+str(float(overall_gu)/total_gu)+\"\\n\")\n",
    "        for (case,score) in sorted(gi_case_accs.items(), key=operator.itemgetter(1)):\n",
    "            case_out.write(str(case)+\":\\n\")\n",
    "            case_out.write(strings[case]+\":\\n\")\n",
    "            case_out.write(\"Grammatical > intrusive: \"+str(round(score,4))+\"\\n\")\n",
    "            case_out.write(\"Grammatical > ungrammatical: \"+str(gu_case_accs[case])+\"\\n\")\n",
    "            case_out.write(\"Intrusive > ungrammatical: \"+str(iu_case_accs[case])+\"\\n\")\n",
    "        case_out.write(\"\\n\")\n",
    "        case_out.close()\n",
    "    \n",
    "    # Individual scores\n",
    "    if MODE == 'full':\n",
    "        fout = open(WORKING_DIR+'/'+model_name+'_individual_accs.txt', 'a')\n",
    "        fout.write(\"\\n##########\\n\" + name + \"\\n##########\\n\\n\")\n",
    "        fout.write(\"Examples where the LM prefers the intrusive licensor over the grammatical case:\\n\")\n",
    "        for case in gi_intrusive_sents.keys():\n",
    "            count = 0\n",
    "            fout.write(case+\":\\n\")\n",
    "            for c,i,u in gi_intrusive_sents[case]:\n",
    "                if count < 5:\n",
    "                    fout.write(\"grammatical:\"+str(round(sum([x[1] for x in c]),2))+\"\\n\")\n",
    "                    fout.write('\\t'.join([x[0] for x in c])+\"\\n\")\n",
    "                    fout.write('\\t'.join([str(round(x[1],2)) for x in c])+\"\\n\")\n",
    "                    fout.write(\"intrusive:\"+str(round(sum([x[1] for x in i]),2))+\"\\n\")\n",
    "                    fout.write('\\t'.join([x[0] for x in i])+\"\\n\")\n",
    "                    fout.write('\\t'.join([str(round(x[1],2)) for x in i])+\"\\n\")\n",
    "                    count += 1\n",
    "                else:\n",
    "                    break\n",
    "        fout.write(\"\\nExamples where the LM prefers the ungrammatical case over the intrusive licensor:\\n\")\n",
    "        for case in iu_ungrammatical_sents.keys():\n",
    "            count = 0\n",
    "            fout.write(case+\":\\n\")\n",
    "            for c,i,u in iu_ungrammatical_sents[case]:\n",
    "                if count < 5:\n",
    "                    fout.write(\"intrusive:\"+str(round(sum([x[1] for x in i]),2))+\"\\n\")\n",
    "                    fout.write('\\t'.join([x[0] for x in i])+\"\\n\")\n",
    "                    fout.write('\\t'.join([str(round(x[1],2)) for x in i])+\"\\n\")\n",
    "                    fout.write(\"ungrammatical:\"+str(round(sum([x[1] for x in u]),2))+\"\\n\")\n",
    "                    fout.write('\\t'.join([x[0] for x in u])+\"\\n\")\n",
    "                    fout.write('\\t'.join([str(round(x[1],2)) for x in u])+\"\\n\")\n",
    "                    count += 1\n",
    "                else:\n",
    "                    break\n",
    "        fout.write(\"\\nExamples where the LM prefers the ungrammatical case over the grammatical case:\\n\")\n",
    "        for case in gu_ungrammatical_sents.keys():\n",
    "            count = 0\n",
    "            fout.write(case+\":\\n\")\n",
    "            for c,i,u in gu_ungrammatical_sents[case]:\n",
    "                if count < 5:\n",
    "                    fout.write(\"grammatical:\"+str(round(sum([x[1] for x in c]),2))+\"\\n\")\n",
    "                    fout.write('\\t'.join([x[0] for x in c])+\"\\n\")\n",
    "                    fout.write('\\t'.join([str(round(x[1],2)) for x in c])+\"\\n\")\n",
    "                    fout.write(\"ungrammatical:\"+str(round(sum([x[1] for x in u]),2))+\"\\n\")\n",
    "                    fout.write('\\t'.join([x[0] for x in u])+\"\\n\")\n",
    "                    fout.write('\\t'.join([str(round(x[1],2)) for x in u])+\"\\n\")\n",
    "                    count += 1\n",
    "                else:\n",
    "                    break\n",
    "        fout.write(\"\\n\")\n",
    "        fout.close()\n",
    "   \n",
    "    return float(overall_gi)/total_gi, float(overall_iu)/total_iu, float(overall_gu)/total_gu\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save a list of results for display later\n",
    "display_results = {}\n",
    "\n",
    "# Iterate through the models to run final analyses\n",
    "for model_name, model_files in model_list.items():\n",
    "    \n",
    "    # Final model analysis\n",
    "    results = pickle.load(open(WORKING_DIR+'/'+model_name+'_results.pickle', 'rb'))\n",
    "    \n",
    "    # Combine results w.r.t. animacy if desired\n",
    "    if not ANIM:\n",
    "        joined_results = {}\n",
    "        for name in tests:\n",
    "            if 'anim' in name:\n",
    "                new_name = '_'.join(name.split(\"_\")[:-1])\n",
    "            else:\n",
    "                new_name = name\n",
    "            for sub_case in results[name]:\n",
    "                if new_name not in joined_results:\n",
    "                    joined_results[new_name] = {}\n",
    "                if sub_case not in joined_results[new_name]:\n",
    "                    joined_results[new_name][sub_case] = []\n",
    "                joined_results[new_name][sub_case] += results[name][sub_case]\n",
    "        pickle.dump(joined_results, open(WORKING_DIR+'/'+model_name+'_results.joined.pickle', 'wb'))\n",
    "    else:\n",
    "        joined_results = results\n",
    "        \n",
    "    # Display and save overall model results\n",
    "    display_results[model_name] = []\n",
    "    with open(WORKING_DIR+'/'+model_name+'_overall_accs.txt', 'w') as f:\n",
    "        for name in joined_results.keys():\n",
    "            if \"npi\" in name:                \n",
    "                if NPI_SKIP:\n",
    "                    continue\n",
    "                sents = analyze_npi_results(joined_results[name])\n",
    "                overall_gi, overall_iu, overall_gu = display_npi_results(name, sents, model_name)\n",
    "                f.write(name+\"(grammatical vs. intrusive): \"+str(overall_gi)+\"\\n\")\n",
    "                f.write(name+\"(intrusive vs. ungrammatical): \"+str(overall_iu)+\"\\n\")\n",
    "                f.write(name+\"(grammatical vs. ungrammatical): \"+str(overall_gu)+\"\\n\")\n",
    "                display_results[model_name].append(overall_gi)\n",
    "                display_results[model_name].append(overall_iu)\n",
    "                display_results[model_name].append(overall_gu)\n",
    "            else:\n",
    "                sents = analyze_agrmt_results(joined_results[name])\n",
    "                overall = display_agrmt_results(name, sents, model_name)\n",
    "                f.write(name+\": \"+str(overall)+\"\\n\")\n",
    "                display_results[model_name].append(overall) \n",
    "     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Display results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VanillaRNN</th>\n",
       "      <th>LSTM</th>\n",
       "      <th>LCRNN</th>\n",
       "      <th>MatureLCRNN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>obj_rel_across</th>\n",
       "      <td>0.550926</td>\n",
       "      <td>0.496914</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.469136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>obj_rel_within</th>\n",
       "      <td>0.646605</td>\n",
       "      <td>0.879630</td>\n",
       "      <td>0.521605</td>\n",
       "      <td>0.569444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>subj_rel</th>\n",
       "      <td>0.515432</td>\n",
       "      <td>0.546296</td>\n",
       "      <td>0.441358</td>\n",
       "      <td>0.370370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prep</th>\n",
       "      <td>0.564815</td>\n",
       "      <td>0.561111</td>\n",
       "      <td>0.455556</td>\n",
       "      <td>0.385185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>obj_rel_no_comp_across</th>\n",
       "      <td>0.513889</td>\n",
       "      <td>0.493827</td>\n",
       "      <td>0.475309</td>\n",
       "      <td>0.476852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>obj_rel_no_comp_within</th>\n",
       "      <td>0.637346</td>\n",
       "      <td>0.691358</td>\n",
       "      <td>0.592593</td>\n",
       "      <td>0.652778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>simple_agrmt</th>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sent_comp</th>\n",
       "      <td>0.810185</td>\n",
       "      <td>0.995370</td>\n",
       "      <td>0.490741</td>\n",
       "      <td>0.495370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vp_coord</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>0.611111</td>\n",
       "      <td>0.527778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>long_vp_coord</th>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>reflexives_across</th>\n",
       "      <td>0.655864</td>\n",
       "      <td>0.554012</td>\n",
       "      <td>0.489198</td>\n",
       "      <td>0.484568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>simple_reflexives</th>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.527778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>reflexive_sent_comp</th>\n",
       "      <td>0.775463</td>\n",
       "      <td>0.706019</td>\n",
       "      <td>0.483796</td>\n",
       "      <td>0.583333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        VanillaRNN      LSTM     LCRNN  MatureLCRNN\n",
       "obj_rel_across            0.550926  0.496914  0.500000     0.469136\n",
       "obj_rel_within            0.646605  0.879630  0.521605     0.569444\n",
       "subj_rel                  0.515432  0.546296  0.441358     0.370370\n",
       "prep                      0.564815  0.561111  0.455556     0.385185\n",
       "obj_rel_no_comp_across    0.513889  0.493827  0.475309     0.476852\n",
       "obj_rel_no_comp_within    0.637346  0.691358  0.592593     0.652778\n",
       "simple_agrmt              0.833333  0.888889  0.444444     0.500000\n",
       "sent_comp                 0.810185  0.995370  0.490741     0.495370\n",
       "vp_coord                  0.500000  0.916667  0.611111     0.527778\n",
       "long_vp_coord             0.555556  0.500000  0.500000     0.500000\n",
       "reflexives_across         0.655864  0.554012  0.489198     0.484568\n",
       "simple_reflexives         0.750000  0.666667  0.444444     0.527778\n",
       "reflexive_sent_comp       0.775463  0.706019  0.483796     0.583333"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract row labels based on test cases\n",
    "labels = []\n",
    "for name in joined_results.keys():\n",
    "    if 'npi' in name:\n",
    "        if NPI_SKIP:\n",
    "            continue\n",
    "        labels.append(name+'(G_v_I)')\n",
    "        labels.append(name+'(I_v_UG)')\n",
    "        labels.append(name+'(G_v_UG)')\n",
    "    else:\n",
    "        labels.append(name)\n",
    "        \n",
    "# Create a dataframe of results and display it\n",
    "df = pd.DataFrame(display_results, index=labels)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Alternatively, show a nice bar plot\n",
    "df.plot.bar(figsize=(15,5))\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Test Case')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
